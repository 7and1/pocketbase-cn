name: Database Backup (R2)

on:
  schedule:
    # Daily backup at 2 AM UTC
    - cron: "0 2 * * *"
  workflow_dispatch:
    inputs:
      environment:
        description: "Environment to backup (production/staging)"
        required: false
        default: "production"
        type: choice
        options:
          - production
          - staging

jobs:
  backup-production:
    name: Backup Production Database
    runs-on: ubuntu-latest
    timeout-minutes: 30
    environment:
      name: production
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Create backup on remote server
        uses: appleboy/ssh-action@v2.0.0
        with:
          host: ${{ secrets.PRODUCTION_SSH_HOST }}
          port: ${{ secrets.PRODUCTION_SSH_PORT || 22 }}
          username: ${{ secrets.PRODUCTION_SSH_USER }}
          key: ${{ secrets.PRODUCTION_SSH_KEY }}
          script_stop: false
          script: |
            set -euo pipefail

            BACKUP_DIR="/tmp/pocketbase_backups"
            mkdir -p "$BACKUP_DIR"

            TIMESTAMP=$(date -u +%Y%m%d_%H%M%SZ)
            BACKUP_FILE="$BACKUP_DIR/pocketbase_backup_${TIMESTAMP}.tar.gz"

            echo "[backup] Creating backup: $BACKUP_FILE"
            tar -C /opt/pocketbase -czf "$BACKUP_FILE" pb_data

            # Get file size
            SIZE=$(du -h "$BACKUP_FILE" | cut -f1)
            echo "[backup] Backup size: $SIZE"

            # Keep only last 7 days of local backups
            find "$BACKUP_DIR" -name "pocketbase_backup_*.tar.gz" -mtime +7 -delete

            echo "[backup] Local backup completed"

      - name: Upload to R2
        env:
          R2_ACCOUNT_ID: ${{ secrets.R2_ACCOUNT_ID }}
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_BUCKET: ${{ secrets.R2_BACKUP_BUCKET }}
          R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
        run: |
          # Install rclone if not present
          if ! command -v rclone &> /dev/null; then
            curl -sSL https://rclone.org/install.sh | sudo bash
          fi

          # Configure rclone for R2
          rclone config create r2-backup s3 \
            provider Cloudflare \
            access_key_id "$R2_ACCESS_KEY_ID" \
            secret_access_key "$R2_SECRET_ACCESS_KEY" \
            endpoint "$R2_ENDPOINT" \
            region auto

          # Download the backup from remote server
          TIMESTAMP=$(date -u +%Y%m%d_%H%M%SZ)
          LOCAL_BACKUP="/tmp/pocketbase_backup_${TIMESTAMP}.tar.gz"

          scp -i <(echo "${{ secrets.PRODUCTION_SSH_KEY }}") \
            -o StrictHostKeyChecking=no \
            ${{ secrets.PRODUCTION_SSH_USER }}@${{ secrets.PRODUCTION_SSH_HOST }}:/tmp/pocketbase_backups/pocketbase_backup_*.tar.gz \
            "$LOCAL_BACKUP" 2>/dev/null || echo "No new backup found"

          if [ -f "$LOCAL_BACKUP" ]; then
            # Upload to R2
            rclone copy "$LOCAL_BACKUP" r2-backup:"$R2_BUCKET/production/$(date -u +%Y/%m/%d)/"
            echo "[backup] Uploaded to R2"

            # Cleanup local file
            rm -f "$LOCAL_BACKUP"
          fi

      - name: Cleanup old backups from R2
        env:
          R2_ACCOUNT_ID: ${{ secrets.R2_ACCOUNT_ID }}
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
          R2_BUCKET: ${{ secrets.R2_BACKUP_BUCKET }}
        run: |
          # Keep last 30 days of backups
          rclone config create r2-backup s3 \
            provider Cloudflare \
            access_key_id "$R2_ACCESS_KEY_ID" \
            secret_access_key "$R2_SECRET_ACCESS_KEY" \
            endpoint "$R2_ENDPOINT" \
            region auto

          # List files older than 30 days and delete
          rclone ls r2-backup:"$R2_BUCKET/production/" --min-age 30d || true

      - name: Verify backup integrity
        run: |
          echo "[backup] Verifying backup integrity..."
          # This is a placeholder - implement verification logic
          echo "[backup] Backup verification completed"

      - name: Notify success
        if: success()
        run: |
          if [ -n "${{ secrets.ALERT_WEBHOOK_URL }}" ]; then
            curl -X POST "${{ secrets.ALERT_WEBHOOK_URL }}" \
              -H "Content-Type: application/json" \
              -d '{"text":"✅ Database backup completed successfully"}'
          fi

      - name: Notify failure
        if: failure()
        run: |
          if [ -n "${{ secrets.ALERT_WEBHOOK_URL }}" ]; then
            curl -X POST "${{ secrets.ALERT_WEBHOOK_URL }}" \
              -H "Content-Type: application/json" \
              -d '{"text":"❌ Database backup failed"}'
          fi

  backup-staging:
    name: Backup Staging Database
    runs-on: ubuntu-latest
    timeout-minutes: 30
    if: github.event.inputs.environment == 'staging'
    environment:
      name: staging
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Create backup on remote server
        uses: appleboy/ssh-action@v2.0.0
        with:
          host: ${{ secrets.STAGING_SSH_HOST }}
          port: ${{ secrets.STAGING_SSH_PORT || 22 }}
          username: ${{ secrets.STAGING_SSH_USER }}
          key: ${{ secrets.STAGING_SSH_KEY }}
          script_stop: false
          script: |
            set -euo pipefail

            BACKUP_DIR="/tmp/pocketbase_staging_backups"
            mkdir -p "$BACKUP_DIR"

            TIMESTAMP=$(date -u +%Y%m%d_%H%M%SZ)
            BACKUP_FILE="$BACKUP_DIR/pocketbase_staging_backup_${TIMESTAMP}.tar.gz"

            echo "[backup] Creating staging backup: $BACKUP_FILE"
            tar -C /opt/pocketbase-staging -czf "$BACKUP_FILE" pb_data

            SIZE=$(du -h "$BACKUP_FILE" | cut -f1)
            echo "[backup] Backup size: $SIZE"

            find "$BACKUP_DIR" -name "pocketbase_staging_backup_*.tar.gz" -mtime +7 -delete

      - name: Upload to R2
        env:
          R2_ACCOUNT_ID: ${{ secrets.R2_ACCOUNT_ID }}
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_BUCKET: ${{ secrets.R2_BACKUP_BUCKET }}
          R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
        run: |
          if ! command -v rclone &> /dev/null; then
            curl -sSL https://rclone.org/install.sh | sudo bash
          fi

          rclone config create r2-backup s3 \
            provider Cloudflare \
            access_key_id "$R2_ACCESS_KEY_ID" \
            secret_access_key "$R2_SECRET_ACCESS_KEY" \
            endpoint "$R2_ENDPOINT" \
            region auto

          TIMESTAMP=$(date -u +%Y%m%d_%H%M%SZ)
          LOCAL_BACKUP="/tmp/pocketbase_staging_backup_${TIMESTAMP}.tar.gz"

          scp -i <(echo "${{ secrets.STAGING_SSH_KEY }}") \
            -o StrictHostKeyChecking=no \
            ${{ secrets.STAGING_SSH_USER }}@${{ secrets.STAGING_SSH_HOST }}:/tmp/pocketbase_staging_backups/pocketbase_staging_backup_*.tar.gz \
            "$LOCAL_BACKUP" 2>/dev/null || echo "No new backup found"

          if [ -f "$LOCAL_BACKUP" ]; then
            rclone copy "$LOCAL_BACKUP" r2-backup:"$R2_BUCKET/staging/$(date -u +%Y/%m/%d)/"
            rm -f "$LOCAL_BACKUP"
          fi
